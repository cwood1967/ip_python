{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from skimage import io\n",
    "from cellpose import models\n",
    "import napari\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = logging.getLogger()\n",
    "r.setLevel(logging.INFO)\n",
    "h = logging.StreamHandler(sys.stdout)\n",
    "h.setLevel(logging.INFO)\n",
    "r.addHandler(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n",
      "VERSION = 2.3.0\n",
      "\n",
      "The bioformats_package.jar is not present.Can only use Python backend for reading/writing images.\n",
      "Resource 'XMLSchema.xsd' is already loaded\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = sorted(glob.glob(\"Data/Training/sample_images/*.tif\"))\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.device('mps')\n",
    "# change gpu=True if on windows, and get rid of device\n",
    "# model = models.Cellpose(gpu=True, model_type='cyto2')\n",
    "model = models.Cellpose(gpu=False, device=d, model_type='cyto2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2044, 2048)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tifffile.imread(images[15])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the image to the viewer. What do you notice about the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'x' at 0x4f2bdbfa0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the cellpose cyto2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masks, flows, _, _ = model.eval(x, channels=[0, 0], diameter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks' at 0x2ffd99000>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label images for training\n",
    "- View image\n",
    "- model.eval the image\n",
    "- add labels\n",
    "- edit the labels\n",
    "- get labels out of the viewer\n",
    "- create a stack with the image and the mask\n",
    "- save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob.glob(\"Data/Training/training_images/*.tif\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list()\n",
    "masks = list()\n",
    "\n",
    "for f in files:\n",
    "    x = tifffile.imread(f)\n",
    "    images.append(x[0])\n",
    "    masks.append(x[1].astype(np.uint16))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> cyto2 << model set to be used\n",
      "WARNING: MKL version on torch not working/installed - CPU version will be slightly slower.\n",
      "see https://pytorch.org/docs/stable/backends.html?highlight=mkl\n",
      ">>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    }
   ],
   "source": [
    "d = torch.device('mps')\n",
    "model = models.CellposeModel(gpu=False, device=d, model_type='cyto2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [01:44<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> median diameter set to = 30\n",
      ">>>> mean of training label mask diameters (saved to model) 124.823\n",
      ">>>> training network with 2 channel input <<<<\n",
      ">>>> LR: 0.20000, batch_size: 32, weight_decay: 0.00001\n",
      ">>>> ntrain = 23\n",
      ">>>> nimg_per_epoch = 24\n",
      "Epoch 0, Time  1.2s, Loss 0.1368, LR 0.0000\n",
      "saving network parameters to models/models/custom\n",
      "Epoch 5, Time  6.7s, Loss 0.1427, LR 0.1111\n",
      "Epoch 10, Time 12.1s, Loss 0.1522, LR 0.2000\n",
      "Epoch 20, Time 22.8s, Loss 0.1412, LR 0.2000\n",
      "Epoch 30, Time 33.6s, Loss 0.1304, LR 0.2000\n",
      "Epoch 40, Time 44.2s, Loss 0.1381, LR 0.2000\n",
      "Epoch 50, Time 54.8s, Loss 0.1446, LR 0.2000\n",
      "Epoch 60, Time 65.5s, Loss 0.1440, LR 0.2000\n",
      "Epoch 70, Time 76.0s, Loss 0.1269, LR 0.2000\n",
      "Epoch 80, Time 86.9s, Loss 0.1439, LR 0.2000\n",
      "Epoch 90, Time 97.5s, Loss 0.1373, LR 0.2000\n",
      "Epoch 100, Time 107.9s, Loss 0.1378, LR 0.2000\n",
      "saving network parameters to models/models/custom\n",
      "Epoch 110, Time 118.5s, Loss 0.1356, LR 0.2000\n",
      "Epoch 120, Time 128.9s, Loss 0.1299, LR 0.2000\n",
      "Epoch 130, Time 139.6s, Loss 0.1298, LR 0.2000\n",
      "Epoch 140, Time 150.1s, Loss 0.1345, LR 0.2000\n",
      "Epoch 150, Time 160.7s, Loss 0.1365, LR 0.2000\n",
      "Epoch 160, Time 171.5s, Loss 0.1151, LR 0.2000\n",
      "Epoch 170, Time 182.6s, Loss 0.1179, LR 0.2000\n",
      "Epoch 180, Time 193.2s, Loss 0.1251, LR 0.2000\n",
      "Epoch 190, Time 204.0s, Loss 0.1156, LR 0.2000\n",
      "Epoch 200, Time 214.8s, Loss 0.1218, LR 0.2000\n",
      "saving network parameters to models/models/custom\n",
      "Epoch 210, Time 225.6s, Loss 0.1183, LR 0.2000\n",
      "Epoch 220, Time 236.4s, Loss 0.1149, LR 0.2000\n",
      "Epoch 230, Time 247.0s, Loss 0.1022, LR 0.2000\n",
      "Epoch 240, Time 257.8s, Loss 0.1214, LR 0.2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnimg_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_train_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/py310/lib/python3.10/site-packages/cellpose/models.py:789\u001b[0m, in \u001b[0;36mCellposeModel.train\u001b[0;34m(self, train_data, train_labels, train_files, test_data, test_labels, test_files, channels, normalize, save_path, save_every, save_each, learning_rate, n_epochs, momentum, SGD, weight_decay, batch_size, nimg_per_epoch, rescale, min_train_masks, model_name)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     models_logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels is set to None, input must therefore have nchan channels (default is 2)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 789\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_flows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_flows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_each\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_each\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mSGD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnimg_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnimg_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model \u001b[38;5;241m=\u001b[39m model_path\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_path\n",
      "File \u001b[0;32m~/mambaforge/envs/py310/lib/python3.10/site-packages/cellpose/core.py:894\u001b[0m, in \u001b[0;36mUnetModel._train_net\u001b[0;34m(self, train_data, train_labels, test_data, test_labels, save_path, save_every, save_each, learning_rate, n_epochs, momentum, weight_decay, SGD, batch_size, nimg_per_epoch, rescale, model_name)\u001b[0m\n\u001b[1;32m    892\u001b[0m rsc \u001b[38;5;241m=\u001b[39m diam_train[inds] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiam_mean \u001b[38;5;28;01mif\u001b[39;00m rescale \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(inds), np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# now passing in the full train array, need the labels for distance field\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m imgi, lbl, scale \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_rotate_and_resize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minds\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minds\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrsc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet \u001b[38;5;129;01mand\u001b[39;00m lbl\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m rescale:\n\u001b[1;32m    898\u001b[0m     lbl[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m scale[:,np\u001b[38;5;241m.\u001b[39mnewaxis,np\u001b[38;5;241m.\u001b[39mnewaxis]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;66;03m#diam_batch[:,np.newaxis,np.newaxis]**2\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/py310/lib/python3.10/site-packages/cellpose/transforms.py:761\u001b[0m, in \u001b[0;36mrandom_rotate_and_resize\u001b[0;34m(X, Y, scale_range, xy, do_flip, rescale, unet, random_per_image)\u001b[0m\n\u001b[1;32m    758\u001b[0m             labels[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlabels[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nchan):\n\u001b[0;32m--> 761\u001b[0m     I \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarpAffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_LINEAR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m     imgi[n,k] \u001b[38;5;241m=\u001b[39m I\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(images, masks, channels=[0, 0], save_path='models', n_epochs=400,\n",
    "            nimg_per_epoch=24, model_name='custom', batch_size=32,\n",
    "            min_train_masks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check how well the model is doing.\n",
    "\n",
    "This model only has 3 return values, so get rid of the last "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tifffile.imread(files[3])[0]\n",
    "masks, flows, _ = model.eval(x, channels=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks' at 0x2e21d84c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(x)\n",
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image' at 0x30059a800>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(flows[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.12733, 3.7140808, 0.2506582)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
