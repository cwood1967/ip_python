{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the imports\n",
    "- If I am doing any processing of files in a folder I like to import os and glob\n",
    "- import cellpose models for training of inferance\n",
    "- import something to read your images \n",
    "- import libraries to save your results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pytorch\n",
    "\n",
    "Use this website to configure the right installation packages:\n",
    "[Pytorch](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "then use `pip install <list of packages>` to install it\n",
    "\n",
    "For my macbook, it is\n",
    "\n",
    "```pip3 install torch torchvision torchaudio```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import tifffile # read an write tiff files\n",
    "from cellpose import models\n",
    "import napari\n",
    "import torch\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Data\"):\n",
    "    url = \"https://www.dropbox.com/s/oga2fhdxbgq2k3h/Data.zip?dl=1\"\n",
    "    utils.download_images(url, \".\")\n",
    "else:\n",
    "    print(\"Data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/a01_42.tif', 'Data/a01_43.tif']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagefiles = sorted(glob.glob(\"Data/*.tif\"))\n",
    "imagefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2160, 2160)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tifffile.imread(\"Data/a01_42.tif\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x2f6a64f40>,\n",
       " <Image layer 'Image [1]' at 0x2f005fd60>,\n",
       " <Image layer 'Image [2]' at 0x2f6fb8ac0>,\n",
       " <Image layer 'Image [3]' at 0x2fc846350>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(x, channel_axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the cellpose model\n",
    "\n",
    "#### GPU setting\n",
    "- on windows or linux with an NVIDIA GPU, set `gpu=True``\n",
    "- on M1 or M2 mac, set `device=torch.device('mps')`\n",
    "- on old Mac or Windows without GPU, set `gpu=False` -- this will be slower\n",
    "\n",
    "#### Model\n",
    "- cellpose has a number of pretrained models to use. Start with `cyto` (even it is nuclei)\n",
    "- Try 'nuclei', 'cyto2', if cyto doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.device('mps')\n",
    "model = models.Cellpose(gpu=False, device=d, model_type='cyto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `model.eval` options\n",
    "\n",
    "The basic options:\n",
    "- x : the image, can be a 2d numpy array, a list of numpy arrays,\n",
    "or a 3d numpy array\n",
    "- diameter : The approximate size of the object you are trying to segment\n",
    "- channels :\n",
    "    - [0, 0] for a grayscale image\n",
    "    - [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, flows, styles, diams = model.eval(x[3], channels=[0, 0],   #[0, 3] might work best\n",
    "                                         diameter=25,\n",
    "                                         cellprob_threshold=-2,\n",
    "                                         flow_threshold=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks1, flows1, styles1, diams1 = model.eval(x[[0, 3], ...], channels=[0, 1],   #[0, 3] might work best\n",
    "                                         diameter=25,\n",
    "                                         cellprob_threshold=-2,\n",
    "                                         flow_threshold=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks1' at 0x390da4310>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(masks)\n",
    "viewer.add_labels(masks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image [4]' at 0x302292ec0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(flows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image [5]' at 0x38b2efd00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(flows[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 3974)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks1.max(), masks.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
