{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1:  Basics of numpy and napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stowers Institue for Medical Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy is the library we will use to handle arrays of data, of which images are but one example\n",
    "import numpy as np\n",
    "\n",
    "# Pandas is a library we will use to handle tabular data, such as the data we will use to store the results of our analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Napari is a library we will use to visualize our images and interact with them\n",
    "import napari\n",
    "\n",
    "# Tifffile is useful for loading tiffs, although there are alternatives in skimage and elsewhere\n",
    "import tifffile\n",
    "\n",
    "# Scikit-image is a library we will use to perform image analysis\n",
    "import skimage as ski\n",
    "\n",
    "# Scipy is a library we will use for some miscellaneous image analysis functions, ndimage was written by the same people as scikit-image, but they have not yet been merged\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# glob is useful for loading lists of files\n",
    "import glob\n",
    "\n",
    "# plotly is a great interactive plotting tool\n",
    "import plotly.express as px\n",
    "\n",
    "# cellpose is a great segmentation tool we will get to later\n",
    "import cellpose.models as models\n",
    "\n",
    "# matplotlib is a plotting library we won't use, but it can show images quickly and easily\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import stackview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the modules we will be using today and for most of the class.  Modules are collections of functions and classes that are not part of the core Python language, but are available for use.  \n",
    "\n",
    "Note that for some of these we used \"import X\", some we used \"import X as Y\", and some we used \"import X.A as A\".  For instance, for \"import napari\", if we wanted to use the function \"Viewer\", we would have to type \"napari.Viewer\".  For \"import numpy as np\", if we want to use the function \"max\" we would have to type \"np.max\".  Modules can have sub-modules, so we might also have to use np.random.randint() at some point.  For the \"import X.A as A\", we are loading a sub-module, or an individual function, and that module/function will be available as \"A\" in our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari is out interactive visualizer.  We will use it to show images and interact with them.  We only want to run this command once, as every time we run it, it creates a new session of napari which is probably not what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"viewer\" is now a variable in our notebook (we could have called it anything, but it is easier to be consistent with other people and use viewer).  \"viewer\" is an object that is going to be our interface between the napari visualizer and our notebook.  We can use it to add images, points, shapes, etc. to the napari window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a notebook imports a function/module that you do not have currently installed, jupyter will let you know with an error message.  If that's the case, then google \"pip <packagename>\" and you will find the name of the library (sometimes it is not the same as the module name, for instance \"skimage\" is actually called \"scikit-image\" when you install it).  Once you find the name you can install it from jupyter using the command \"!pip install <packagename>\" as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stackview in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: numpy!=1.19.4 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (1.23.4)\n",
      "Requirement already satisfied: ipycanvas in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (0.13.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (8.1.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (0.20.0)\n",
      "Requirement already satisfied: ipyevents in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (2.0.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (0.12.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (3.8.1)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stackview) (6.26.0)\n",
      "Requirement already satisfied: pillow>=6.0 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipycanvas->stackview) (10.0.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipywidgets->stackview) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipywidgets->stackview) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipywidgets->stackview) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipywidgets->stackview) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipywidgets->stackview) (3.0.9)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (8.5.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (1.5.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipykernel->stackview) (6.3.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from matplotlib->stackview) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from matplotlib->stackview) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from matplotlib->stackview) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from matplotlib->stackview) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from matplotlib->stackview) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from matplotlib->stackview) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from scikit-image->stackview) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from scikit-image->stackview) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from scikit-image->stackview) (2.31.6)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from scikit-image->stackview) (2023.9.26)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from scikit-image->stackview) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from scikit-image->stackview) (0.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->stackview) (0.4.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->stackview) (3.11.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->stackview) (306)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stackview) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->stackview) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets->stackview) (0.2.9)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->stackview) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->stackview) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->stackview) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install stackview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stackview is a crude multi-dimensional visualizer that works within jupyter.  It is not as nice as napari, but it is very easy to install and use, and works on remote machines which is a very big deal in some situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we are going to load an example image avaialble in skimage.  Later we will load our own images.  All images need to be assigned to a variable, and we can decide the name of the variable to suit our needs,  we will call it img for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ski.data.camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot to unpack in this line.  ski.data.camera finds a function in skimage called \"camera\", it is in the \"data\" sub-module, that's why we have to chain multiple \".\" together.  The function \"camera\" returns an image, which we then assign to the variable \"img\".  We can then use the variable \"img\" to access the image.  We will be using lots and lots of functions in the class, so it is important to understand how to use them.\n",
    "\n",
    "A function is a collection of code that does something.  In this case, the function \"camera\" returns an image.  Functions can take inputs, and they can return outputs.  In this case, the function \"camera\" does not take any inputs, but it returns an image.  \n",
    "\n",
    "This next function \"viewer.add_image()\" DOES take an input, and if it returns an output we are not really interested in it, we are only interested in the function doing what it is supposed to do: displaying our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x20223751ae0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly every line of code we write will have a function in it, so as you're looking at them, try to ask yourself a few questions:  \n",
    "\n",
    "What is the function's name?  \n",
    "What module is it coming from (if any)?  \n",
    "What inputs does it take?  \n",
    "What does it return?  \n",
    "What does it do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need any help with these, you can google, or you can just use the ? function as below, just replace where you would put the parentheses with a question mark and it will give you the documentation for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchannel_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrgb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcontrast_limits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minterpolation2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minterpolation3d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrendering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mip'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdepiction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'volume'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0miso_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mattenuation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtranslate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrotate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mshear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maffine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mopacity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mblending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvisible\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmultiscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mplane\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexperimental_clipping_planes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcustom_interpolation_kernel_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'Union[Image, List[Image]]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Add an image layer to the layer list.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : array or list of array\n",
      "    Image data. Can be N >= 2 dimensional. If the last dimension has length\n",
      "    3 or 4 can be interpreted as RGB or RGBA if rgb is `True`. If a\n",
      "    list and arrays are decreasing in shape then the data is treated as\n",
      "    a multiscale image. Please note multiscale rendering is only\n",
      "    supported in 2D. In 3D, only the lowest resolution scale is\n",
      "    displayed.\n",
      "channel_axis : int, optional\n",
      "    Axis to expand image along.  If provided, each channel in the data\n",
      "    will be added as an individual image layer.  In channel_axis mode,\n",
      "    all other parameters MAY be provided as lists, and the Nth value\n",
      "    will be applied to the Nth channel in the data.  If a single value\n",
      "    is provided, it will be broadcast to all Layers.\n",
      "rgb : bool or list\n",
      "    Whether the image is rgb RGB or RGBA. If not specified by user and\n",
      "    the last dimension of the data has length 3 or 4 it will be set as\n",
      "    `True`. If `False` the image is interpreted as a luminance image.\n",
      "    If a list then must be same length as the axis that is being\n",
      "    expanded as channels.\n",
      "colormap : str, napari.utils.Colormap, tuple, dict, list\n",
      "    Colormaps to use for luminance images. If a string must be the name\n",
      "    of a supported colormap from vispy or matplotlib. If a tuple the\n",
      "    first value must be a string to assign as a name to a colormap and\n",
      "    the second item must be a Colormap. If a dict the key must be a\n",
      "    string to assign as a name to a colormap and the value must be a\n",
      "    Colormap. If a list then must be same length as the axis that is\n",
      "    being expanded as channels, and each colormap is applied to each\n",
      "    new image layer.\n",
      "contrast_limits : list (2,)\n",
      "    Color limits to be used for determining the colormap bounds for\n",
      "    luminance images. If not passed is calculated as the min and max of\n",
      "    the image. If list of lists then must be same length as the axis\n",
      "    that is being expanded and then each colormap is applied to each\n",
      "    image.\n",
      "gamma : list, float\n",
      "    Gamma correction for determining colormap linearity. Defaults to 1.\n",
      "    If a list then must be same length as the axis that is being\n",
      "    expanded as channels.\n",
      "interpolation : str or list\n",
      "    Deprecated, to be removed in 0.6.0\n",
      "interpolation2d : str or list\n",
      "    Interpolation mode used by vispy in 2D. Must be one of our supported\n",
      "    modes. If a list then must be same length as the axis that is being\n",
      "    expanded as channels.\n",
      "interpolation3d : str or list\n",
      "    Interpolation mode used by vispy in 3D. Must be one of our supported\n",
      "    modes. If a list then must be same length as the axis that is being\n",
      "    expanded as channels.\n",
      "rendering : str or list\n",
      "    Rendering mode used by vispy. Must be one of our supported\n",
      "    modes. If a list then must be same length as the axis that is being\n",
      "    expanded as channels.\n",
      "depiction : str\n",
      "    Selects a preset volume depiction mode in vispy\n",
      "\n",
      "    * volume: images are rendered as 3D volumes.\n",
      "    * plane: images are rendered as 2D planes embedded in 3D.\n",
      "iso_threshold : float or list\n",
      "    Threshold for isosurface. If a list then must be same length as the\n",
      "    axis that is being expanded as channels.\n",
      "attenuation : float or list\n",
      "    Attenuation rate for attenuated maximum intensity projection. If a\n",
      "    list then must be same length as the axis that is being expanded as\n",
      "    channels.\n",
      "name : str or list of str\n",
      "    Name of the layer.  If a list then must be same length as the axis\n",
      "    that is being expanded as channels.\n",
      "metadata : dict or list of dict\n",
      "    Layer metadata. If a list then must be a list of dicts with the\n",
      "    same length as the axis that is being expanded as channels.\n",
      "scale : tuple of float or list\n",
      "    Scale factors for the layer. If a list then must be a list of\n",
      "    tuples of float with the same length as the axis that is being\n",
      "    expanded as channels.\n",
      "translate : tuple of float or list\n",
      "    Translation values for the layer. If a list then must be a list of\n",
      "    tuples of float with the same length as the axis that is being\n",
      "    expanded as channels.\n",
      "rotate : float, 3-tuple of float, n-D array or list.\n",
      "    If a float convert into a 2D rotation matrix using that value as an\n",
      "    angle. If 3-tuple convert into a 3D rotation matrix, using a yaw,\n",
      "    pitch, roll convention. Otherwise assume an nD rotation. Angles are\n",
      "    assumed to be in degrees. They can be converted from radians with\n",
      "    np.degrees if needed. If a list then must have same length as\n",
      "    the axis that is being expanded as channels.\n",
      "shear : 1-D array or list.\n",
      "    A vector of shear values for an upper triangular n-D shear matrix.\n",
      "    If a list then must have same length as the axis that is being\n",
      "    expanded as channels.\n",
      "affine : n-D array or napari.utils.transforms.Affine\n",
      "    (N+1, N+1) affine transformation matrix in homogeneous coordinates.\n",
      "    The first (N, N) entries correspond to a linear transform and\n",
      "    the final column is a length N translation vector and a 1 or a\n",
      "    napari `Affine` transform object. Applied as an extra transform on\n",
      "    top of the provided scale, rotate, and shear values.\n",
      "opacity : float or list\n",
      "    Opacity of the layer visual, between 0.0 and 1.0.  If a list then\n",
      "    must be same length as the axis that is being expanded as channels.\n",
      "blending : str or list\n",
      "    One of a list of preset blending modes that determines how RGB and\n",
      "    alpha values of the layer visual get mixed. Allowed values are\n",
      "    {'opaque', 'translucent', and 'additive'}. If a list then\n",
      "    must be same length as the axis that is being expanded as channels.\n",
      "visible : bool or list of bool\n",
      "    Whether the layer visual is currently being displayed.\n",
      "    If a list then must be same length as the axis that is\n",
      "    being expanded as channels.\n",
      "multiscale : bool\n",
      "    Whether the data is a multiscale image or not. Multiscale data is\n",
      "    represented by a list of array like image data. If not specified by\n",
      "    the user and if the data is a list of arrays that decrease in shape\n",
      "    then it will be taken to be multiscale. The first image in the list\n",
      "    should be the largest. Please note multiscale rendering is only\n",
      "    supported in 2D. In 3D, only the lowest resolution scale is\n",
      "    displayed.\n",
      "cache : bool\n",
      "    Whether slices of out-of-core datasets should be cached upon\n",
      "    retrieval. Currently, this only applies to dask arrays.\n",
      "plane : dict or SlicingPlane\n",
      "    Properties defining plane rendering in 3D. Properties are defined in\n",
      "    data coordinates. Valid dictionary keys are\n",
      "    {'position', 'normal', 'thickness', and 'enabled'}.\n",
      "experimental_clipping_planes : list of dicts, list of ClippingPlane, or ClippingPlaneList\n",
      "    Each dict defines a clipping plane in 3D in data coordinates.\n",
      "    Valid dictionary keys are {'position', 'normal', and 'enabled'}.\n",
      "    Values on the negative side of the normal are discarded if the plane is enabled.\n",
      "custom_interpolation_kernel_2d : np.ndarray\n",
      "    Convolution kernel used with the 'custom' interpolation mode in 2D rendering.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "layer : :class:`napari.layers.Image` or list\n",
      "    The newly-created image layer or list of image layers.\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages\\napari\\components\\viewer_model.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "viewer.add_image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Napari viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the napari viewer a bit, it is pretty intuitive:  zooming with the mousewheel, clicking and dragging the image around, etc.  Also as you mouse over a pixel value, you can see its value and your current location in the bottom left of the viewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLOR:  To change the color of a displayed image or channel, use the \"colormap\" dropdown.\n",
    "\n",
    "CONTRAST:  To adjust the brightness/contrast:  use the \"contrast limits\" sliders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load another image that is a bit more like the data we will be looking at in the future.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ski.data.cells3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets rid of the camera image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x20228931840>,\n",
       " <Image layer 'Image [1]' at 0x20228ab7e50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(img, channel_axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this time we provided two arguments to the \"add_image\" function.  The first is the image we want to display, the second is the location of the two channels of our image in the numpy array, we will get to that in more detail later.  But you should have a 2 color image of cells now, and a new slider at the bottom of the viewer for sliding through the z-slices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around a bit with the image, in the bottom left there are a few buttons that become more interesting with multi-channel and multi-dimensional data.  The second button, \"ndisplay\", lets you visualize in 3D, ala Imaris.  Clicking and dragging will let you rotate the image.  The third and fourth buttons let you swap two of the axes, effectively \"reslicing\" the data.  The fifth button lets you display the colors side by side, useful for colorblind people like me.  \n",
    "\n",
    "To turn off/on individual channels you can click the icon that looks like an eye in the channel list.  You can likewise change the color of individual channels using \"colormap\" as before.\n",
    "\n",
    "\"blending\" is also something to be aware of, by default images get added in \"translucent mode\", but if you choose that for the green image you will find you no longer see the magenta one.  If you want to be able to see the current channel AND all of the channels behind it, you have to choose \"additive\" blending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw from above view_image takes a lot of different arguments, let's play with some of them (we will use viewer.layers.clear() inbetween to clear the viewer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'cells' at 0x20255cf3f70>,\n",
       " <Image layer 'cells [1]' at 0x202883f4fd0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1, name='cells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us give the layer a name.  We can also give arguments a list of values, one entry for however many channels are in our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'membrane' at 0x202289314e0>,\n",
       " <Image layer 'nucleus' at 0x202886e2080>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1, name=['membrane', 'nucleus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or change the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'membrane' at 0x202887477f0>,\n",
       " <Image layer 'nucleus' at 0x202886b01c0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1, name=['membrane', 'nucleus'], colormap=['red', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'membrane' at 0x20288654dc0>,\n",
       " <Image layer 'nucleus' at 0x20255d22680>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1, name=['membrane', 'nucleus'], colormap=['red', 'blue'], contrast_limits=[[0, 10000], [0, 20000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the scaling of each pixel (usually our z-resolution is lower than our x/y resolution, so we can scale the z-axis to make it look more isotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1, name=['membrane', 'nucleus'], colormap=['red', 'blue'], contrast_limits=[[0, 30000], [0, 50000]], scale=[1, 0.5, 0.5])\n",
    "viewer.dims.ndisplay = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viewer.dims.ndisplay is not a function, it is a variable contained within viewer.dims that we can set whenever we want.  viewer.dims.ndisplay = 3 forces the viewer to show in the 3D mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.dims.ndisplay = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape and type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \"img\"?  It is an array.  This just means it is a collection of numbers (usually either integral or floating point), arranged in a grid of rows and columns for simple images like this one.  We can see the size of the array by using the \"shape\" attribute of the array.  We can also see the type of the array by using the \"dtype\" attribute.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go back to the camera-man example, we can see our image is very simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200, 200, 200, ..., 189, 190, 190],\n",
       "       [200, 199, 199, ..., 190, 190, 190],\n",
       "       [199, 199, 199, ..., 190, 190, 190],\n",
       "       ...,\n",
       "       [ 25,  25,  27, ..., 139, 122, 147],\n",
       "       [ 25,  25,  26, ..., 158, 141, 168],\n",
       "       [ 25,  25,  27, ..., 151, 152, 149]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ski.data.camera()\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 3D cell image, our shape is more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2060, 2058, 2126, ..., 4283, 4091, 4074],\n",
       "         [2008, 1952, 2029, ..., 4188, 3739, 3996],\n",
       "         [1963, 2299, 1911, ..., 4157, 4465, 4051],\n",
       "         ...,\n",
       "         [1105, 1169, 1140, ..., 2700, 2880, 3233],\n",
       "         [1159, 1068, 1126, ..., 2981, 3266, 3415],\n",
       "         [ 967, 1120, 1124, ..., 2748, 3043, 3558]],\n",
       "\n",
       "        [[5311, 4458, 5880, ..., 4220, 6497, 4932],\n",
       "         [4078, 4552, 3557, ..., 4552, 4884, 5169],\n",
       "         [3414, 5074, 4363, ..., 4078, 6117, 5406],\n",
       "         ...,\n",
       "         [3983, 3983, 2750, ..., 4410, 4600, 5880],\n",
       "         [3604, 4173, 4600, ..., 5548, 5690, 4268],\n",
       "         [4078, 4268, 4220, ..., 5359, 6686, 7492]]],\n",
       "\n",
       "\n",
       "       [[[1804, 2066, 2052, ..., 3909, 3806, 4047],\n",
       "         [1874, 1917, 2008, ..., 3797, 3582, 4051],\n",
       "         [2008, 1950, 2037, ..., 3911, 4093, 3830],\n",
       "         ...,\n",
       "         [1233, 1078,  990, ..., 1690, 2056, 2014],\n",
       "         [ 899, 1277,  923, ..., 1880, 2180, 2116],\n",
       "         [ 938, 1190, 1043, ..., 1994, 1766, 1936]],\n",
       "\n",
       "        [[4220, 4932, 5074, ..., 6449, 6117, 4932],\n",
       "         [3082, 4979, 4505, ..., 4505, 6971, 5880],\n",
       "         [4695, 4315, 4695, ..., 4742, 5785, 5074],\n",
       "         ...,\n",
       "         [3414, 3841, 3462, ..., 5169, 4742, 5027],\n",
       "         [4173, 3319, 2798, ..., 5406, 4600, 4837],\n",
       "         [3225, 3557, 3651, ..., 5453, 5406, 4837]]],\n",
       "\n",
       "\n",
       "       [[[1998, 2240, 2271, ..., 3690, 3859, 3727],\n",
       "         [1857, 2175, 2237, ..., 4049, 3894, 3948],\n",
       "         [1975, 1954, 2056, ..., 3733, 4031, 3708],\n",
       "         ...,\n",
       "         [1091, 1134, 1159, ..., 1799, 1758, 1925],\n",
       "         [1041, 1027, 1045, ..., 1750, 1835, 1928],\n",
       "         [1122, 1202, 1198, ..., 2060, 1740, 1979]],\n",
       "\n",
       "        [[4552, 4505, 4742, ..., 4458, 4979, 4647],\n",
       "         [3367, 4268, 4647, ..., 6402, 6022, 5738],\n",
       "         [3509, 3272, 4647, ..., 5264, 4220, 6259],\n",
       "         ...,\n",
       "         [3841, 3936, 3888, ..., 4884, 5169, 4789],\n",
       "         [3604, 3225, 2798, ..., 4552, 6117, 5690],\n",
       "         [4126, 4458, 4837, ..., 5928, 6734, 5027]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[5111, 4991, 3361, ..., 2275, 2289, 2337],\n",
       "         [4715, 6425, 5051, ..., 2452, 2428, 2355],\n",
       "         [3142, 3789, 4198, ..., 2163, 2413, 2413],\n",
       "         ...,\n",
       "         [1178, 1295, 1252, ...,  576,  457,  564],\n",
       "         [1322, 1314, 1322, ...,  591,  607,  512],\n",
       "         [1266, 1341, 1345, ...,  434,  504,  535]],\n",
       "\n",
       "        [[5121, 5833, 5738, ..., 5406, 3983, 4220],\n",
       "         [5311, 5453, 5453, ..., 5169, 5027, 4884],\n",
       "         [6544, 5121, 5264, ..., 4363, 5406, 4695],\n",
       "         ...,\n",
       "         [4884, 2324, 3130, ..., 4552, 4979, 6070],\n",
       "         [3225, 2513, 2513, ..., 4742, 3035, 2418],\n",
       "         [3272, 2798, 3888, ..., 3604, 4268, 3746]]],\n",
       "\n",
       "\n",
       "       [[[4175, 4194, 3233, ..., 2124, 2066, 1998],\n",
       "         [4029, 4836, 3801, ..., 2200, 2078, 2223],\n",
       "         [2940, 3217, 3128, ..., 2202, 2163, 2227],\n",
       "         ...,\n",
       "         [1320, 1308, 1304, ...,  663,  415,  500],\n",
       "         [1076, 1258, 1062, ...,  576,  533,  523],\n",
       "         [1235, 1050, 1382, ...,  477,  322,  609]],\n",
       "\n",
       "        [[5359, 5928, 5738, ..., 4268, 4505, 4031],\n",
       "         [7445, 6829, 4268, ..., 4884, 5596, 3082],\n",
       "         [6497, 6544, 4932, ..., 3604, 5359, 4410],\n",
       "         ...,\n",
       "         [5833, 2703, 3367, ..., 3177, 4220, 4220],\n",
       "         [4031, 3509, 5216, ..., 4268, 3604, 4932],\n",
       "         [3557, 2987, 3936, ..., 3604, 3462, 5264]]],\n",
       "\n",
       "\n",
       "       [[[3049, 3252, 2692, ..., 1870, 2016, 1882],\n",
       "         [3165, 3297, 2863, ..., 1944, 2120, 2052],\n",
       "         [2857, 2632, 2578, ..., 1851, 2029, 1907],\n",
       "         ...,\n",
       "         [1386, 1138, 1066, ...,  516,  597,  415],\n",
       "         [1151, 1227, 1304, ...,  640,  576,  479],\n",
       "         [1012, 1167, 1279, ...,  572,  498,  448]],\n",
       "\n",
       "        [[6402, 6781, 4789, ..., 5928, 6022, 3651],\n",
       "         [4363, 4837, 6307, ..., 4315, 3651, 4126],\n",
       "         [4979, 4695, 4742, ..., 4789, 4837, 4552],\n",
       "         ...,\n",
       "         [4078, 2513, 3035, ..., 1849, 3888, 4363],\n",
       "         [3936, 3888, 4315, ..., 5216, 4031, 5643],\n",
       "         [4173, 4505, 3794, ..., 4979, 6781, 4031]]]], dtype=uint16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ski.data.cells3d()\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our numbers are bigger, we have uint16 instead of uint8, meaning pixel brightnesses can range from 0-65535 instead of 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2, 256, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our shape is more complicated, the last two numbers are the Y and X dimensions (256 each), while the second number represents how many channels we have (in this case 2 for the two different colors), and the first number represents how many z-slices we have (in this case 60).\n",
    "\n",
    "You can think of these as simply lists of 2D images stacked on top of each other and organized into Z*C (this is actually how numpy views them anyway).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to access a pixel, we use the slicing functionality of arrays, we will ask for the pixel at position 128,128 in the first channel, at the 20th z-slice.  Note that python is 0-indexed, so the first channel is actually 0, and the second channel is actually 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4171"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[19,0,127,127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even extract a whole image.  Let's say we want the 26th slice from the 2nd channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'my_slice' at 0x2028853b310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = img[25,1,:,:]\n",
    "\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(my_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \":\" by itself to indicate we want all of the values in that dimension.  We can also combine it with numbers to extract a range of values.  Let's say we want the 26th slice from the 2nd channel, but only the first 100 pixels in the x-dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'my_cropped' at 0x20288a36d70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cropped = img[25,1,:,0:100]\n",
    "\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(my_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting thing about slicing is that if we create a variable that slices into another array (as we have with \"my_cropped\"), then if we change the values in \"my_cropped\", we also change the values in \"img\".  This is because \"my_cropped\" is not a copy of \"img\", it is a \"view\" into \"img\".  This is a very useful for saving space, but can sometimes have un-intended consequences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x20288b5ca90>,\n",
       " <Image layer 'Image [1]' at 0x20288bc5ed0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cropped[:] = 0\n",
    "\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sometimes when working with slices it is better to make a copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x20288b339a0>,\n",
       " <Image layer 'Image [1]' at 0x20288909120>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ski.data.cells3d()\n",
    "my_cropped = np.copy(img[25,1,:,0:100])\n",
    "\n",
    "my_cropped[:] = 0\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy makes it very easy to make projections of arrays, let's say we want to do a max projection of our cells3d image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65535"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ski.data.cells3d()\n",
    "\n",
    "max_projection = np.max(img)\n",
    "max_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't quite what we wanted, we wanted it to just project over the z-dimension, giving us a 2X256X256 image.  np.max has an argument that lets us specify which dimension we want to find the max over.  Remember this is python, so if we have a 4D array, the axis of the first dimension is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2, 256, 256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 256, 256)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_projection = np.max(img, axis=0)\n",
    "max_projection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing with a mean projection and then display them both in napari.  Note that since we have gotten rid of the z-dimension, our channel_axis is now 0 instead of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_projection = np.mean(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Mean' at 0x2028853bc70>,\n",
       " <Image layer 'Mean [1]' at 0x202888cdcc0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(max_projection, channel_axis=0, name='Max')\n",
    "viewer.add_image(mean_projection, channel_axis=0, name='Mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images into napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ski.io.imread('files/Neuromast.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I always do when opening a new strange image is look at its shape, as there is no consistency on which dimension is channels, time, slices etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 70, 2, 262, 291)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the channels are in the 3rd slot, so we can show in napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x202888cf820>,\n",
       " <Image layer 'Image [1]' at 0x20288519150>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=2, scale=[1,0.5,.16,.16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other file types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pt 1:  Load Neuromast.tif into napari again, but change the colors to red and gray.  Adjust the contrast so that the background in both channels is removed.  Switch to 3D mode and take a screenshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x2028867d5a0>,\n",
       " <Image layer 'Image [1]' at 0x202876cef50>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ski.io.imread('files/Neuromast.tif')\n",
    "\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(img, channel_axis=2, scale=[1,0.5,.16,.16], colormap=['red', 'gray'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pt 2:  Find the dividing cell, crop down to just it in x, y, and z, make sure you include the proper scaling (0.5 in z, 0.16 in and X and Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Image layer 'Image' at 0x2028b52dcf0>,\n",
       " <Image layer 'Image [1]' at 0x20288474970>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "sub_img = img[:,24:40, :, 0:48, 72:120]\n",
    "viewer.add_image(sub_img, channel_axis=2, scale=[1,0.5,.16,.16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pt 3:  Take your cropped image and make 3 new images, each a max projection in one direction.  Display all 3 in napari, you will have to use the add_image 3 times, and to see them individually will have to toggle on/off their visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'X' at 0x20288cb7e80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_z = np.max(sub_img[:,:,1], axis=1)\n",
    "sub_y = np.max(sub_img[:,:,1], axis=2)\n",
    "sub_x = np.max(sub_img[:,:,1], axis=3)\n",
    "\n",
    "viewer.layers.clear()\n",
    "viewer.add_image(sub_z, scale=[.16,.16], name='Z')\n",
    "viewer.add_image(sub_y, scale=[.16,.16], name='Y')\n",
    "viewer.add_image(sub_x, scale=[.16,.16], name='X')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe have them open some new file type we haven't done yet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
